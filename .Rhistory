ses_goog_dif = ses(goog.dif,
alpha = 0.2,
h = 100)
ses_goog_dif = ses(goog_dif,
alpha = 0.2,
h = 100)
summary(ses_goog_dif)
autoplot(ses_goog_dif)
ses_goog_dif = ses(goog_dif,
alpha = 0.1:0.9,
h = 100)
summary(ses_goog_dif)
ses_goog_dif = ses(goog_dif,
alpha = 0.9,
h = 100)
summary(ses_goog_dif)
ses_goog_dif = ses(goog_dif,
alpha = 0.01,
h = 100)
summary(ses_goog_dif)
autoplot(ses_goog_dif)
ses_goog_dif = ses(goog_dif,
alpha = 0.2,
h = 100)
summary(ses_goog_dif)
autoplot(ses_goog_dif)
### Dados de teste:
goog_dif_test = diff(goog_test)
accuracy(object = ses_goog_dif, goog_dif_test)
autoplot(ses_goog_dif)
### código linha 130 - aplicando Holt Winter
holt_goog = holt(y = goog_train, h = 100)
summary(holt_goog)
autoplot(holt_goog)
autoplot(holt_goog)
holt_goog$model
accuracy(holt_goog, goog_test)
autoplot(holt_goog)
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(qcement)
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(diff(x = qcement, lag = 1))
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(diff(x = qcement, lag = 0))
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(diff(x = qcement, lag = 3))
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(diff(x = qcement))
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(qcement)
?qcement
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(qcement)
qcement_train = window(x = qcement, end = c(2012, 4))
qcement_test = window(x = qcement, start = c(2013, 1))
autoplot(qcement)
autoplot(qcement_test)
decompose(qcement)
autoplot(decompose(qcement))
pacotes <- c("fpp2","tidyverse","gridExtra","data.table","ggseas","knitr","zoo")
sapply(X = pacotes, FUN = require, character = TRUE)
# ações do google:
goog
plot(goog)
goog_train = window(goog, end = 900)
goog_test = window(goog, start = 901)
# carregando qcement
plot(qcement)
qcement_train = window(qcement, end = c(2012, 4))
qcement_test = window(qcement, start = c(2013,1))
# Suavização Exponencial Simples - somente alpha
ses_goog = ses(y = goog_train, alpha = 0.2, h = 100)
summary(ses_goog)
autoplot(ses_goog)
# removendo a tendência
goog_dif = diff(goog_train)
autoplot(goog_dif)
acf(goog_dif)
ses_goog_dif = ses(goog_dif,
alpha = 0.2,
h = 100)
summary(ses_goog_dif)
autoplot(ses_goog_dif)
### Dados de teste:
goog_dif_test = diff(goog_test)
accuracy(object = ses_goog_dif, goog_dif_test)
autoplot(ses_goog_dif)
### código linha 130 - aplicando Holt
holt_goog = holt(y = goog_train, h = 100)
summary(holt_goog)
autoplot(holt_goog)
holt_goog$model
accuracy(holt_goog, goog_test)
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(qcement)
qcement_train = window(x = qcement, end = c(2012, 4))
qcement_test = window(x = qcement, start = c(2013, 1))
autoplot(qcement_test)
autoplot(decompose(qcement)) # observe que o componente sazonal tem nível constante (método aditivo)
#### modelo aditivo com a função ets
### code 245
?ets
#### modelo aditivo com a função ets
### code 245
qcement_hw = ets(y = qcement_train, model = "AAA") # ets ( exponencial smoothing state space)
summary(qcement_hw)
autoplot(forecast(qcement_hw))
autoplot(forecast(qcement_hw, h = 30))
autoplot(forecast(qcement_hw, h = 200))
autoplot(forecast(qcement_hw, h = 1000))
autoplot(forecast(qcement_hw, h = 10000))
autoplot(forecast(qcement_hw, h = 100000))
autoplot(forecast(qcement_hw, h = 24))
checkresiduals(qcement_hw)
# acuracia para os proximos 5 quadrimestres
qcement_hw_predict = forecast(qcement_hw, h = 5)
accuracy(qcement_hw_predict, qcement_test)
### Testando o ets para o modelo multiplicativo:
qcement_hw_mult = ets(y = qcement_train, model = "MAM") # Ruídos multiplicativo. Tendencia Aditiva. Seazonal: Multiplicativo
smmary(qcement_hw_mult)
summary(qcement_hw_mult)
checkresiduals(qcement_hw_mult)
qcement_hw_mult_pred = forecast(object = qcement_hw_mult, h = 5)
autoplot(qcement_hw_mult_pred)
accuracy(qcement_hw_mult_pred, qcement_test)
#### Exemplo 6
#### code 340
nzbop
#### Exemplo 6
#### code 340
nzbop = nzbop
str(nzbop)
View(nzbop)
?nzbop
ts(nzbop)
nzbop[, trend := rollmean(value, 8, fill = NA, align = "right")]
nzbop[, trend := rollmean(value, 8, fill = NA, align = "right")]
nzbop[, trend == rollmean(value, 8, fill = NA, align = "right")]
:=
nzbop[, trend := rollmean(value, 8, fill = NA, align = "right")]
120.00 + ((1493.54 - 120.00)*0.1) + 6.0
120.00 + ((1493.54 - 120.00)*0.1) + 6.0
air_payment = function(total, clean_tx){
day_10 = 0.1 * (total - clean_tx)
return(clean_tx + day_10)
}
air_payment(total = 963.87, clean_tx = 120.00)
air_payment(total = 963.87, clean_tx = 120.00)
setwd("D:/atividades/atividades/pos_usp_data_science_analitycs/tcc/data/data/2/")
getwd()
# libraries
library(tidyverse)
library(reshape2)
# read csv and select some colums # Remove observations without grades
enade_2019 = read.csv(file = "MICRODADOS_ENEM_2019.csv", sep = ";")
enade_2019 = enade_2019 %>%
select(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA, NU_NOTA_CN, NU_NOTA_CH, NU_NOTA_LC, NU_NOTA_MT, NU_NOTA_REDACAO) %>%
filter( (NU_NOTA_CN != "NA") & (NU_NOTA_CH != "NA") & (NU_NOTA_LC != "NA") & (NU_NOTA_MT != "NA") )
# structure of data:
str(enade_2019)
# summary of data
summary(enade_2019)
# prepare data to melt in a unique boxplot - to verify grade distributions
data_for_box = melt(enade_2019[c("NU_NOTA_CN", "NU_NOTA_CH", "NU_NOTA_LC", "NU_NOTA_MT")])
ggplot(data_for_box) + aes(x = variable, y = value) + geom_boxplot()
rm(data_for_box) # clean data memory
# the grades are nearly distributed in a aproximate range
# lets try to work with a unified grade
# unified grade = mean from c("NU_NOTA_CN", "NU_NOTA_CH", "NU_NOTA_LC", "NU_NOTA_MT")
# mutate dataFrame to calculate the means of grades by cities code:
enade_2019_with_mean = enade_2019 %>%
mutate(media_CN_CH_LC_MT = (NU_NOTA_CN + NU_NOTA_CH + NU_NOTA_LC + NU_NOTA_MT) /4 ) %>%
select(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA,media_CN_CH_LC_MT) %>%
data.frame()
View(enade_2019_with_mean)
View(enade_2019)
View(enade_2019_with_mean)
teste_enade = enade_2019_with_mean %>%
mutate(mean_grades_group_cities = mean(media_CN_CH_LC_MT)) %>%
group_by(CO_MUNICIPIO_RESIDENCIA)
View(teste_enade)
teste_enade = enade_2019_with_mean %>%
mutate(mean_grades_group_cities = mean(media_CN_CH_LC_MT)) %>%
group_by(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA)
View(teste_enade)
teste_enade = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA) %>%
mutate(mean_grades_group_cities = mean(media_CN_CH_LC_MT))
View(teste_enade)
teste_enade = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA) %>%
mutate(mean_grades_group_cities = mean(media_CN_CH_LC_MT)) %>%
select(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA, mean_grades_group_cities)
View(teste_enade)
teste_enade = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA) %>%
mutate(mean_grades_group_cities = mean(media_CN_CH_LC_MT)) %>%
select(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA, mean_grades_group_cities) %>%
group_by(CO_MUNICIPIO_RESIDENCIA)
View(teste_enade)
View(teste_enade)
teste_enade = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA) %>%
mutate(mean_grades_group_cities = mean(media_CN_CH_LC_MT)) %>%
select(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA, mean_grades_group_cities) %>%
group_by(CO_MUNICIPIO_RESIDENCIA)
View(teste_enade)
teste_enade = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA) %>%
summarize(mean_grades_group_cities = mean(media_CN_CH_LC_MT, na.rm = TRUE))
View(teste_enade)
teste_enade = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA) %>%
summarize(mean_grades_group_cities = round(mean(media_CN_CH_LC_MT, na.rm = TRUE)), 2)
teste_enade = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA) %>%
summarize(mean_grades_group_cities = mean(media_CN_CH_LC_MT, na.rm = TRUE))
hist(teste_enade$mean_grades_group_cities)
View(enade_2019_with_mean)
teste_enade = enade_2019_with_mean %>%
select(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA)
View(teste_enade)
teste_enade = enade_2019_with_mean %>%
select(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA, media_CN_CH_LC_MT) %>%
group_by(CO_MUNICIPIO_RESIDENCIA) %>%
summarize(mean_grades_group_cities = mean(media_CN_CH_LC_MT, na.rm = TRUE))
View(teste_enade)
teste_enade = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA) %>%
summarize(mean_grades_group_cities = mean(media_CN_CH_LC_MT, na.rm = TRUE))
View(teste_enade)
teste_2019_summarize = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA) %>%
summarize(mean_grades_group_cities = mean(media_CN_CH_LC_MT, na.rm = TRUE)) %>%
data.frame()
rm(teste_enade)
rm(enade_2019_with_mean)
enade_2019_summarize = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA) %>%
summarize(mean_grades_group_cities = mean(media_CN_CH_LC_MT, na.rm = TRUE)) %>%
data.frame()
# mutate dataFrame to calculate the means of all grades:
enade_2019_with_mean = enade_2019 %>%
mutate(media_CN_CH_LC_MT = (NU_NOTA_CN + NU_NOTA_CH + NU_NOTA_LC + NU_NOTA_MT) / 4 ) %>%
select(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA,media_CN_CH_LC_MT) %>%
data.frame()
enade_2019_summarize = enade_2019_with_mean %>%
group_by(CO_MUNICIPIO_RESIDENCIA, NO_MUNICIPIO_RESIDENCIA, SG_UF_RESIDENCIA) %>%
summarize(mean_grades_group_cities = mean(media_CN_CH_LC_MT, na.rm = TRUE)) %>%
data.frame()
View(enade_2019_summarize)
rm(enade_2019)
rm(enade_2019_with_mean)
rm(teste_2019_summarize)
View(enade_2019_summarize)
# Write file to a new Processed Enade CSV
write_csv(x = enade_2019_summarize, file = "enade_2019_summary_mean_grade_by_citie.csv")
setwd("d:/atividades/atividades/pos_usp_data_science_analitycs/tcc/data/data/processed_files/")
getwd()
library(dplyr)
teste = read.csv("01_enade_2019_summary_mean_grade_by_citie.csv")
View(teste)
hist(teste$mean_grades_group_cities)
min(mean(teste$mean_grades_group_cities))
min(teste$mean_grades_group_cities)
summary(teste$mean_grades_group_cities)
sd(teste$mean_grades_group_cities)
setwd("D:/atividades/atividades/pos_usp_data_science_analitycs/tcc/data/data/processed_files/")
getwd()
# libraries
library(tidyverse)
library(reshape2)
# read csv and select some colums # Remove observations without grades
enade_2019 = read.csv(file = "MICRODADOS_ENEM_2019.csv", sep = ";")
setwd("D:/atividades/atividades/pos_usp_data_science_analitycs/tcc/data/data/")
getwd()
# read csv and select some colums # Remove observations without grades
enade_2019 = read.csv(file = "2/MICRODADOS_ENEM_2019.csv", sep = ";")
View(enade_2019)
setwd("d:/atividades/atividades/pos_usp_data_science_analitycs/tcc/data/data/processed_files/")
getwd()
pnad = read.csv("PES2015.txt")
View(pnad)
pnad = read.csv("PES2015.txt", sep = ";")
View(pnad)
`dicPME` <-
structure(list(cod = structure(c(2L, 3L, 4L, 5L, 6L, 7L, 8L,
10L, 9L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
22L, 23L, 24L, 25L, 33L, 36L, 37L, 26L, 27L, 28L, 29L, 30L, 31L,
32L, 34L, 35L, 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L,
48L, 49L, 50L, 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L,
61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L,
74L, 75L, 76L, 182L, 77L, 183L, 78L, 79L, 80L, 81L, 82L, 83L,
184L, 84L, 185L, 85L, 86L, 87L, 88L, 89L, 90L, 91L, 92L, 94L,
93L, 95L, 96L, 97L, 98L, 186L, 99L, 100L, 187L, 101L, 102L, 103L,
104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L,
115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L,
126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L,
137L, 138L, 150L, 151L, 139L, 140L, 141L, 142L, 143L, 144L, 145L,
1L, 146L, 147L, 148L, 149L, 152L, 163L, 173L, 174L, 175L, 176L,
177L, 178L, 179L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L,
161L, 162L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L, 172L,
180L, 181L), .Label = c(" V464", "V035", "V040", "V050", "V055",
"V060", "V063", "V070", "V072", "V075", "V104", "V105", "V106",
"V107", "V108", "V109", "V110", "V111", "V112", "V113", "V114",
"V115", "V201", "V203", "V204", "V205", "V206", "V207", "V208",
"V209", "V210", "V211", "V214", "V215", "V218", "V224", "V234",
"V301", "V302", "V303", "V304", "V305", "V306", "V307", "V308",
"V309", "V310", "V311", "V312", "V313", "V314", "V401", "V402",
"V403", "V404", "V405", "V4051", "V4052", "V4053", "V4054", "V406",
"V407A", "V408A", "V409", "V410", "V411", "V412", "V4121", "V4122",
"V413", "V414", "V415", "V416", "V417", "V418", "V4182", "V4191",
"V420", "V421", "V422", "V4221", "V4222", "V4231", "V4241", "V425",
"V426", "V4261", "V4262", "V427", "V4271", "V4272", "V4273",
"V4274", "V4275", "V428", "V429", "V430", "V4302", "V431", "V4312",
"V432", "V433", "V434", "V435", "V436", "V437", "V438", "V439",
"V440", "V441", "V442", "V443", "V444", "V445A", "V446A", "V447",
"V448", "V449", "V450", "V451", "V452", "V4521", "V4522", "V4523",
"V4524", "V453", "V454", "V4541", "V4542", "V4543", "V4544",
"V455", "V456", "V457", "V458", "V459", "V460", "V461", "V462",
"V463", "V4631", "V4632", "V4633", "V4634", "V4635", "V465",
"V466", "V467", "V468", "V471", "V481", "VD1", "VD10", "VD11",
"VD12", "VD13", "VD14", "VD15", "VD16", "VD17", "VD18", "VD19",
"VD2", "VD20", "VD21", "VD22", "VD23", "VD24", "VD25", "VD26",
"VD27", "VD28", "VD3", "VD4", "VD5", "VD6", "VD7", "VD8", "VD9",
"VDAE1", "VDAE2", "VI4182", "VI4191", "VI4231", "VI4241", "VI4302",
"VI4312"), class = "factor"), inicio = c(1, 3, 11, 16, 17, 18,
19, 21, 25, 26, 27, 28, 31, 44, 59, 63, 69, 73, 79, 84, 93, 102,
104, 105, 107, 109, 113, 117, 118, 119, 120, 121, 123, 125, 132,
139, 149, 150, 151, 153, 154, 155, 156, 158, 159, 160, 161, 162,
163, 164, 165, 166, 167, 168, 170, 171, 173, 175, 177, 179, 180,
183, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197,
198, 207, 216, 225, 234, 235, 236, 237, 238, 240, 249, 258, 267,
276, 277, 278, 279, 281, 282, 284, 286, 288, 290, 292, 295, 298,
299, 308, 317, 318, 327, 336, 337, 339, 341, 342, 343, 344, 346,
347, 348, 349, 350, 351, 352, 355, 357, 358, 359, 360, 361, 362,
363, 365, 367, 369, 371, 372, 373, 375, 377, 379, 381, 382, 383,
385, 386, 387, 389, 391, 393, 397, 399, 400, 402, 404, 406, 408,
410, 411, 412, 413, 416, 417, 418, 419, 420, 421, 422, 423, 424,
425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,
438, 439, 448, 457, 466, 475, 478, 481, 482), tamanho = c(2,
8, 5, 1, 1, 1, 2, 4, 1, 1, 1, 3, 13, 15, 4, 6, 4, 6, 5, 9, 9,
2, 1, 2, 2, 4, 4, 1, 1, 1, 1, 2, 2, 7, 7, 10, 1, 1, 2, 1, 1,
1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 3, 2,
1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 1, 1, 1, 1, 2,
9, 9, 9, 9, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 3, 3, 1, 9, 9, 1, 9,
9, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1,
1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 4, 2,
1, 2, 2, 2, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9, 9, 3, 3, 1, 1),
desc = c("RM", "Numero de controle", "Numero de serie", "Semana",
"Painel", "Grupo rotacional", "Mes da Pesquisa", "Ano da pesquisa",
"Numero da pesquisa no domicilio", "Tipo de entrevista",
"Especie do domicilio", "Numero de setores selecionados",
"Probabilidade do setor", "Intervalo de Selecao do domicilio",
"Total de domicilios selecionados no setor", "Total de domicilios listados no setor",
"Fracao de amostragem", "Strat", "PSU", "Projecao de populacao",
"Salario Minimo", "Numero de ordem", "Sexo", "Dia de nascimento",
"Mes de nascimento", "Ano de nascimento", "Idade calculada",
"Condicao no domicilio", "Condicao na familia", "Numero da familia",
"Cor ou raca", "Total de moradores", "Total de moradores de 10 anos ou mais",
"Pesocor1", "Pesoexp1", "Espaco em branco com 10 posicoes",
"1 - Sabe ler e escrever?", "2 - Frequenta escola?", "3 - Qual o curso que frequenta?",
"4 - O curso e seriado?", "5 - Qual e a serie que frequenta?",
"6 - Anteriormente, frequentou escola?", "7 - Curso de grau mais elevado que frequentou",
"8 - Este curso anterior era seriado?", "9 - Pelo menos 1a serie concluida no curso anterior?",
"10 - Ultima serie concluida com aprovacao", "11 - Concluiu este curso anterior?",
"12 - Concluiu algum curso de qualificacao profissional?",
"13 - Frequenta curso de qualificacao profissional?", "14 - Nivel de escolaridade exigido para esse curso",
"Trabalho remunerado na semana de referencia?", "Trabalho nao remunerado na semana de referencia?",
"Temporariamente afastado de algum trab. sem. ref?", "Motivo do afastamento",
"Tempo de afastamento antes da sem. ref.", "Tempo em dias de afastamento antes da sem. ref.",
"Tempo em meses de afastamento antes da sem. ref.", "Tempo em anos de afastamento antes da sem. ref.",
"Tempo em meses de afastamento antes da sem. ref., apos 1 ano",
"Quantos trabalhos tinha na semana de ref.?", "Variavel auxiliar de ocupacao (Dia)",
"Variavel auxiliar de atividade (Dia)", "Nesse trabalho era:",
"Prestava servico domestico remun. em mais de 1 domic.?",
"Esse emprego era no setor", "Grupo de numero de pessoas ocupadas nesse empreendimento",
"Numero de pessoas ocupadas nesse empreendimento (2 a 5)",
"Numero de pessoas ocupadas nesse empreendimento (6 a 10)",
"Esse emprego era na area", "Era militar ou empregado pelo RJU?",
"Tinha carteira de trabalho assinada?", "Era contribuinte de instituto de previdencia?",
"Prazo de contrato determinado ou indeterminado", "Rendimento bruto mensal habitual ou em beneficios",
"Rendimento bruto mensal habitual em reais", "Rendimento bruto mensal habitual em reais imputado",
"Rendimento mensal bruto efetivo no mes de referencia", "Rendimento mensal bruto efetivo no mes ref. imputado",
"Era membro de cooperativa?", "Tinha pelo menos um empregado na sem. ref.?",
"Numero de empregados (grupos)", "Numero de empregados (1 a 5)",
"Numero de empregados (6 a 10)", "Retirada mensal habitual",
"Retirada mensal habitual imputado", "Retirada mensal efetiva mes ref.",
"Retirada mensal efetiva mes ref.", "Era contribuinte de instituto de previdencia?",
"Numero de pessas ocupadas na sem. ref. (grupos)", "Numero de pessas ocupadas na sem. ref. (1 a 5)",
"Numero de pessas ocupadas na sem. ref.(6 a 10)", "Tempo de trabalho antes da sem. ref. (grupos)",
"Dias de trabalho antes da sem ref.", "Meses de trabalho antes da sem ref.",
"Anos de trabalho antes da sem ref.(1 a 2)", "Meses de trabalho antes da sem ref. apos 1 ou 2 anos",
"Anos de trabalho antes da sem ref.(+ de 2)", "Horas de trabalho habituais por semana",
"Horas de trabalho  sem.ref.", "Rendimento mensal habitual outro trab. sem.ref.(grupos)",
"Rendimento mensal habitual outro trab. sem.ref.(reais)",
"Rend. mensal habitual outro trab. sem.ref.(reais) imputado",
"Sabia informar rend. efetivo no mes ref. do outro trabalho",
"Rend. efetivo no mes ref. do outro trabalho (reais)", "Rend. efetivo no mes ref. do outro trabalho imputado",
"Contr. instit. prev. outro trabalho", "Horas trab. habituais outro trabalho",
"Horas trab. efetivamente outro trabalho", "Gostaria de trabalhar alem do tempo habitual sem. ref.",
"Estava disponivel para trab. alem do tempo que trabalhou",
"No mes ref. estaria dispon. trabalhar alem tempo trabalhou",
"Quantas horas/sem poderia trabalhar alem trabalhou sem.ref.",
"No ultimo dia da sem. ref. ainda tinha algum trabalho?",
"Procurou trabalho sem.ref. depois que saiu do trab. sem.ref.",
"Procurou trabalho per.ref. 365d enquanto estava nesse trab.",
"Teve algum trab. remun. antes sem. ref.?", "Teve algum trab. nao remun. antes sem. ref.",
"Saiu algum trab per. captacao 358 dias?", "Variavel auxiliar de ocupacao (Dia)",
"Variavel auxiliar de atividade (Dia)", "Nesse ultimo trabalho que teve era",
"Nesse ultimo trabalho era militar ou empregado RJU?", "Nesse ultimo trabalho tinha carteira de trabalho assinada?",
"Estava contratado por prazo determinado ou indeterminado?",
"Saiu desse ultimo trabalho porque", "Quanto tempo ficou nesse ultimo trabalho?(grupos)",
"Quantos meses ficou nesse ultimo trabalho?(<1ano)", "Quantos anos ficou nesse ultimo trabalho?(>=1a e <2a)",
"Quantos anos ficou nesse ultimo trabalho?(2a ou mais)",
"Quantos meses ficou nesse ultimo trabalho?(>=1a e <2a)",
"Saiu desse ultimo trabalho per. capt. 23 dias?", "Tempo que saiu do trabalho (grupos)",
"Tempo que saiu do trabalho meses (1m a 11m)", "Tempo que saiu do trabalho anos (>=1a e <2a)",
"Tempo que saiu do trabalho anos (2a ou +)", "Tempo que saiu do trabalho meses (>=1a e <2a)",
"Depois que saiu procurou trabalho per.ref.365d?", "Tomou providencia para conseguir trabalho per.ref.365d",
"Qual ultima providencia p/ conseguir trabalho per.ref.365d?",
"Tomou essa providencia na semana referencia?", "Tomou essa providencia no periodo de captacao de 23 dias?",
"Ha quanto tempo tomou essa providencia?", "Em que data tomou esta ultima providencia? DIA",
"Em que data tomou esta  ultima providencia? MES", "Em que data tomou esta ultima providencia? ANO",
"Por que nao tomou providencia conseguir trabalho per.ref.30d",
"Tempo procurou trab. antes provid (grupos)", "Tempo procurou trab. antes provid (dias, <=30d)",
"Tempo procurou trab. antes provid (meses, >=31d e <1a)",
"Tempo procurou trab. antes provid (anos, >=1a e <2a)", "Tempo procurou trab. antes provid (anos, >=2a)",
"Tempo procurou trab. antes provid (meses, >=1a e <2a)",
"Embora nao tenha procurado gostaria de conseguir trabalho?",
"Se conseguisse trabalho, poderia assumi-lo na sem.ref.",
"Se conseguisse trabalho, poderia assumi-lo no per.cap.23d?",
"Quantas horas por semana poderia dedicar a esse trabalho?",
"A entrevista foi realizada com a propria pessoa?", "Condicao de ocupacao na semana de referencia",
"Desocupado", "Economicamente ativo na semana de referencia - PEA",
"Marginalmente ligado a PEA na semana de referencia", "Desencorajado (Desalentado) na semana de referencia",
"Subocupado trabalhando menos de 40h/sem sem.ref.", "Ocupado Sub-Remunerado",
"Ocupado no periodo de referencia de 365 dias", "Saiu do ultimo trabalho per.ref. 365 dias",
"Desocupado procurando trabalho (cons disponib)", "Desocupado procurando trabalho (consid. disponib.)",
"Desocupado procur. trab. per.ref.30d.", "Desocupado periodo referencia 365 dias",
"Desocupado procur. trab. per.ref.30d., por tempo procura",
"Desocupado por posicao ocupacao e categoria emprego", "Empregado segundo setor do trabalho principal",
"Empregado segundo setor e posse de carteira trabalho", "Empregado segundo tipo de contrato",
"Ocupado segundo num pessoas ocupadas", "Ocupado segundo secoes de atividade do trabalho principal",
"Ocupado segundo contribuicao para Instituto da Previdencia",
"Ocupado procurando trabalho per.ref. 30 dias", "Rendimento mensal habitual referente ao trabalho principal",
"Rendimento mensal efetivo mes referencia trabalho principal.",
"Rendimento mensal habitual todos os trabalhos", "Rendimento mensal efetivo mes referencia todos os trabalhos.",
"Numero horas/sem habitualmente trabalhadas todos os trabalhos",
"Numero de horas/sem efetivas sem.ref. todos os trabalhos",
"anos de estudos I", "anos de estudos II")), .Names = c("cod",
"inicio", "tamanho", "desc"), row.names = c("1", "2", "3", "4",
"5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15",
"16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26",
"27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37",
"38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48",
"49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59",
"60", "61", "62", "63", "64", "65", "66", "67", "68", "69", "70",
"71", "72", "73", "74", "75", "76", "77", "78", "79", "80", "81",
"82", "83", "84", "85", "86", "87", "88", "89", "90", "91", "92",
"93", "94", "95", "96", "97", "98", "99", "100", "101", "102",
"103", "104", "105", "106", "107", "108", "109", "110", "111",
"112", "113", "114", "115", "116", "117", "118", "119", "120",
"121", "122", "123", "124", "125", "126", "127", "128", "129",
"130", "131", "132", "133", "134", "135", "136", "137", "138",
"139", "140", "141", "142", "143", "144", "145", "146", "147",
"148", "149", "150", "151", "152", "153", "154", "155", "156",
"157", "158", "159", "160", "161", "162", "163", "164", "165",
"166", "167", "168", "169", "170", "171", "172", "173", "174",
"175", "176", "177", "178", "179", "180", "181", "182", "183",
"184", "185", "186", "187"), class = "data.frame")
View(dicPME)
install.packages("PNADcIBGE")
library(PNADcIBGE)
library(tidyverse)
pnad_2019 = get_pnadc(year = 2019, design = FALSE, interview = 1)
View(pnad_2019)
getwd()
read_csv("Acessos_Banda_Larga_Fixa_2019_2020_Colunas.csv", sep=";")
internet = read.csv("Acessos_Banda_Larga_Fixa_2019_2020_Colunas.csv", sep = ";")
View(internet)
unique(internet$Faixa.de.Velocidade)
unique(internet$Tecnologia)
sum(internet$X2019.12)
sum(internet$X2019.12, na.rm = TRUE)
sum(internet$X2019.01, na.rm = TRUE)
sum(internet$X2020.12, na.rm = TRUE)
