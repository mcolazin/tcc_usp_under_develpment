pacotes <- c("plotly","tidyverse","knitr","kableExtra","reshape2","ggrepel",
"fastDummies","lmtest","splines","jtools","questionr","MASS",
"pscl","overdisp","magick","cowplot","beepr")
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
library(dplyr)
library(tidyverse)
pacotes <- c("datasets","forecast","fpp2","tseries","patchwork", "DataCombine", "TTR")
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
AirPassengers
passengers = AirPassengers
plot.ts(passengers)
plotly(plot.ts(passengers))
plot.ts(passengers)
plot.ts(passengers)
lag(passengers,k = -2)
ts_data = ts(passengers)
ts_data
lagts = lag(ts_data, 3)
lagts
my_df = as.data.frame(ts_data)
View(my_df)
my_df = slide(data = my_df, Var = "x", NewVar = "x_lag1", slideBy = -1)
my_df = slide(data = my_df, Var = "x", NewVar = "x_lead1", slideBy = 1)
fpp2::a10
plot.ts(fpp2::a10)
# autocorrelação - acf()
acf(a10)
pacf(a10) # correlação parcial
ggtsdisplay(a10)
# estacionariedade
rb = ts(rnorm(500))
rb
autoplot(rb)
var(rb)
# normalidade
hist(rnorm(5000))
hist(a10)
qqnorm(a10)
qqline(a10, col = "red")
qqline(a10)
# formatand gráfico
plot(USAccDeaths)
# formatand gráfico
plot(USAccDeaths, type = 'o')
# combinando graficos TS
plot.ts(USAccDeaths)
# combinando graficos TS
plot.ts(AirPassengers)
# combinando graficos TS
USAccDeaths
# combinando graficos TS
AirPassengers
# combinando graficos TS
cbind(USAccDeaths, AirPassengers)
# combinando graficos TS
plot.ts(cbind(USAccDeaths, AirPassengers))
# Funções Agregação
aggregate(x = USAccDeaths, nfrequency = 4, FUN = sum) # agregação trimestral
# media anual
aggregate(x = USAccDeaths, nfrequency = 1, FUN = mean)
plot(USAccDeaths)
plot(aggregate(USAccDeaths))
plot(aggregate(USAccDeaths, nfrequency = 4, FUN = sum))
monthplot(x = USAccDeaths, col.base = 2, labels = month.abb)
# janela temporal
janela = window(x = USAccDeaths, start = c(1973, 5), end = c(1975, 7))
janela
plot(janela)
diff(USAccDeaths)
USAccDeaths
USAccDeaths[1973]
USAccDeaths["1973"]
USAccDeaths["1973"]["Jan"]
USAccDeaths[1,1]
USAccDeaths[1]
USAccDeaths[1]-USAccDeaths[2]
# Analise de autocorrelacao fac e parcial pfac
a = acf(USAccDeaths, lag.max = 25)
a
# Analise de autocorrelacao fac e parcial pfac
a = acf(USAccDeaths, lag.max = 1)
a
# Analise de autocorrelacao fac e parcial pfac
a = acf(USAccDeaths, lag.max = 2)
a
# Analise de autocorrelacao fac e parcial pfac
a = acf(USAccDeaths, lag.max = 25)
a
a
p = pacf(x = USAccDeaths, lag.max = 25)
p
da = acf(diff(USAccDeaths), lag.max = 25)
# avaliação da sazonalidade:
stl(log(USAccDeaths), "periodic")
plot(stl(log(USAccDeaths), "periodic"))
install.packages("ggseas")
pacotes <- c("fpp2","tidyverse","gridExtra","data.table","ggseas","knitr","zoo")
sapply(X = pacotes, FUN = require, character = TRUE)
# ações do google:
goog
plot(goog)
plot.ts(goog, frequency = 1)
plot.ts(goog)
plot.ts(ts(goog, frequency = 1))
plot.ts(ts(goog, frequency = 12))
plot(goog)
goog_train = window(goog, end = 900)
goog_test = window(goog, start = 901)
# carregando airpessengers
qcement
# carregando qcement
plot(qcement)
qcement_train = window(qcement, end = c(2012, 4))
qcement_test = window(qcement, start = c(2013,1))
# Suavização Exponencial Simples - somente alpha
ses_goog = ses(y = goog_train, alpha = 0.2, h = 100)
summary(ses_goog)
autoplot(ses_goog)
# removendo a tendência
goog_dif = diff(goog_train)
autoplot(goog_dif)
acf(goog_dif)
ses_goog_dif = ses(goog.dif,
alpha = 0.2,
h = 100)
ses_goog_dif = ses(goog_dif,
alpha = 0.2,
h = 100)
summary(ses_goog_dif)
autoplot(ses_goog_dif)
ses_goog_dif = ses(goog_dif,
alpha = 0.1:0.9,
h = 100)
summary(ses_goog_dif)
ses_goog_dif = ses(goog_dif,
alpha = 0.9,
h = 100)
summary(ses_goog_dif)
ses_goog_dif = ses(goog_dif,
alpha = 0.01,
h = 100)
summary(ses_goog_dif)
autoplot(ses_goog_dif)
ses_goog_dif = ses(goog_dif,
alpha = 0.2,
h = 100)
summary(ses_goog_dif)
autoplot(ses_goog_dif)
### Dados de teste:
goog_dif_test = diff(goog_test)
accuracy(object = ses_goog_dif, goog_dif_test)
autoplot(ses_goog_dif)
### código linha 130 - aplicando Holt Winter
holt_goog = holt(y = goog_train, h = 100)
summary(holt_goog)
autoplot(holt_goog)
autoplot(holt_goog)
holt_goog$model
accuracy(holt_goog, goog_test)
autoplot(holt_goog)
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(qcement)
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(diff(x = qcement, lag = 1))
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(diff(x = qcement, lag = 0))
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(diff(x = qcement, lag = 3))
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(diff(x = qcement))
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(qcement)
?qcement
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(qcement)
qcement_train = window(x = qcement, end = c(2012, 4))
qcement_test = window(x = qcement, start = c(2013, 1))
autoplot(qcement)
autoplot(qcement_test)
decompose(qcement)
autoplot(decompose(qcement))
pacotes <- c("fpp2","tidyverse","gridExtra","data.table","ggseas","knitr","zoo")
sapply(X = pacotes, FUN = require, character = TRUE)
# ações do google:
goog
plot(goog)
goog_train = window(goog, end = 900)
goog_test = window(goog, start = 901)
# carregando qcement
plot(qcement)
qcement_train = window(qcement, end = c(2012, 4))
qcement_test = window(qcement, start = c(2013,1))
# Suavização Exponencial Simples - somente alpha
ses_goog = ses(y = goog_train, alpha = 0.2, h = 100)
summary(ses_goog)
autoplot(ses_goog)
# removendo a tendência
goog_dif = diff(goog_train)
autoplot(goog_dif)
acf(goog_dif)
ses_goog_dif = ses(goog_dif,
alpha = 0.2,
h = 100)
summary(ses_goog_dif)
autoplot(ses_goog_dif)
### Dados de teste:
goog_dif_test = diff(goog_test)
accuracy(object = ses_goog_dif, goog_dif_test)
autoplot(ses_goog_dif)
### código linha 130 - aplicando Holt
holt_goog = holt(y = goog_train, h = 100)
summary(holt_goog)
autoplot(holt_goog)
holt_goog$model
accuracy(holt_goog, goog_test)
#### Holt_Winters
## Codigo 224
## modelo aditivo - estrutura sazonal com magnitude igual ou consistente
### modelo multipliativo -  estrutura sazonal de dados aumenta ao longo do tempo
autoplot(qcement)
qcement_train = window(x = qcement, end = c(2012, 4))
qcement_test = window(x = qcement, start = c(2013, 1))
autoplot(qcement_test)
autoplot(decompose(qcement)) # observe que o componente sazonal tem nível constante (método aditivo)
#### modelo aditivo com a função ets
### code 245
?ets
#### modelo aditivo com a função ets
### code 245
qcement_hw = ets(y = qcement_train, model = "AAA") # ets ( exponencial smoothing state space)
summary(qcement_hw)
autoplot(forecast(qcement_hw))
autoplot(forecast(qcement_hw, h = 30))
autoplot(forecast(qcement_hw, h = 200))
autoplot(forecast(qcement_hw, h = 1000))
autoplot(forecast(qcement_hw, h = 10000))
autoplot(forecast(qcement_hw, h = 100000))
autoplot(forecast(qcement_hw, h = 24))
checkresiduals(qcement_hw)
# acuracia para os proximos 5 quadrimestres
qcement_hw_predict = forecast(qcement_hw, h = 5)
accuracy(qcement_hw_predict, qcement_test)
### Testando o ets para o modelo multiplicativo:
qcement_hw_mult = ets(y = qcement_train, model = "MAM") # Ruídos multiplicativo. Tendencia Aditiva. Seazonal: Multiplicativo
smmary(qcement_hw_mult)
summary(qcement_hw_mult)
checkresiduals(qcement_hw_mult)
qcement_hw_mult_pred = forecast(object = qcement_hw_mult, h = 5)
autoplot(qcement_hw_mult_pred)
accuracy(qcement_hw_mult_pred, qcement_test)
#### Exemplo 6
#### code 340
nzbop
#### Exemplo 6
#### code 340
nzbop = nzbop
str(nzbop)
View(nzbop)
?nzbop
ts(nzbop)
nzbop[, trend := rollmean(value, 8, fill = NA, align = "right")]
nzbop[, trend := rollmean(value, 8, fill = NA, align = "right")]
nzbop[, trend == rollmean(value, 8, fill = NA, align = "right")]
:=
nzbop[, trend := rollmean(value, 8, fill = NA, align = "right")]
120.00 + ((1493.54 - 120.00)*0.1) + 6.0
120.00 + ((1493.54 - 120.00)*0.1) + 6.0
air_payment = function(total, clean_tx){
day_10 = 0.1 * (total - clean_tx)
return(clean_tx + day_10)
}
air_payment(total = 963.87, clean_tx = 120.00)
air_payment(total = 963.87, clean_tx = 120.00)
library(PNADcIBGE)
library(tidyverse)
# Carregamento dos dados do Pnad 2019
pnad_2019 = get_pnadc(year = 2019, design = FALSE, interview = 1)
View(pnad_2019)
unique(pnad_2019$Capital)
# Dicionário
# - UF - Unidade da Federação
# VD4019 - Rendimento Mensal Efetivo
teste = pnad_2019 %>%
select(VD4019, UF)
View(teste)
# Dicionário
# - UF - Unidade da Federação
# VD4019 - Rendimento Mensal Efetivo
teste = pnad_2019 %>%
select(VD4019, UF) %>%
group_by(UF) %>%
summarise(remuneracao_media = mean(VD4019))
# Dicionário
# - UF - Unidade da Federação
# VD4019 - Rendimento Mensal Efetivo
teste = pnad_2019 %>%
select(VD4019, UF) %>%
group_by(UF) %>%
summarise(remuneracao_media = mean(VD4019, na.rm = TRUE))
# Dicionário
# - UF - Unidade da Federação
# VD4019 - Rendimento Mensal Efetivo
teste = pnad_2019 %>%
select(VD4019, UF) %>%
group_by(UF) %>%
summarise(remuneracao_media = round(mean(VD4019, na.rm = TRUE), digits = 2))
# Dicionário
# - UF - Unidade da Federação
# VD4019 - Rendimento Mensal Efetivo
teste = pnad_2019 %>%
select(VD4019, UF) %>%
group_by(UF) %>%
summarise(remuneracao_media = round(mean(VD4019, na.rm = TRUE), digits = 2)) %>%
data.frame()
View(pnad_2019)
pnad_2019 %>%
select(UF, VD4019) %>%
filter(UF == "Paraná")
remuner_pr = pnad_2019 %>%
select(UF, VD4019) %>%
filter(UF == "Paraná")
View(remuner_pr)
mean(remuner_pr$VD4019)
mean(remuner_pr$VD4019, na.rm = TRUE)
hist(remuner_pr$VD4019)
rm(pnad_2019)
rm(remuner_pr)
remuneracao_mean_uf = teste
View(remuneracao_mean_uf)
library(PNADcIBGE)
library(tidyverse)
# Carregamento dos dados do Pnad 2019
pnad_2019 = get_pnadc(year = 2019, design = FALSE, interview = 1)
library(PNADcIBGE)
library(tidyverse)
# Carregamento dos dados do Pnad 2019
pnad_2019 = get_pnadc(year = 2019, design = FALSE, interview = 1)
# Dicionário
# - UF - Unidade da Federação
# VD4019 - Rendimento Mensal Efetivo
# Média das Remunerações po UF:
remuneracao_uf_mean_sd = pnad_2019 %>%
select(VD4019, UF) %>%
group_by(UF) %>%
summarise(remuneracao_media = round(mean(VD4019, na.rm = TRUE), digits = 2),
desvio_padrao = round( sqrt(var(VD4019, na.rm = TRUE)),digits = 2  )) %>%
data.frame()
View(remuneracao_uf_mean_sd)
remuneracao_uf_mean_sd$UF
# Alterar os dados dos municípios
list_municipio = remuneracao_uf_mean_sd$UF
View(list_municipio)
remuneracao_uf_mean_sd_renamed = remuneracao_uf_mean_sd %>%
mutate(UF = recode(UF,
"Rondônia" = "RO",
"Rondônia" = "AC",
"Amazonas" = "AM"))
View(remuneracao_uf_mean_sd_renamed)
remuneracao_uf_mean_sd_renamed = remuneracao_uf_mean_sd %>%
mutate(UF = recode(UF,
"Rondônia" = "RO",
"Acre" = "AC",
"Amazonas" = "AM"))
remuneracao_uf_mean_sd_renamed = remuneracao_uf_mean_sd %>%
mutate(UF = recode(UF,
"Rondônia" = "RO",
"Acre" = "AC",
"Amazonas" = "AM",
"Roraima" = "RR",
"Pará" = "PA",
"Amapá" = "AP",
"Tocantins" = "TO",
"Maranhão" = "MA"))
View(remuneracao_uf_mean_sd_renamed)
pacotes <- c("rgdal","raster","tmap","maptools","sf","rgeos","sp","adehabitatHR",
"tidyverse","broom","rayshader","knitr","kableExtra","RColorBrewer",
"profvis")
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
setwd("D:/atividades/atividades/pos_usp_data_science_analitycs/tcc/data/data/3 ibge_pib_idh_gini/")
getwd()
library(tidyverse)
read.csv("PIB dos Municípios - base de dados 2010-2019.txt")
read.delim("PIB dos Municípios - base de dados 2010-2019.txt")
read.delim("PIB dos Municípios - base de dados 2010-2019.txt", sep = " ")
test = read.delim("PIB dos Municípios - base de dados 2010-2019.txt")
View(test)
test = read.delim("pib_municipios_ibge_editado_excell.csv")
test = read.csv("pib_municipios_ibge_editado_excell.csv")
View(test)
test = read.csv("pib_municipios_ibge_editado_excell.csv", sep = ";", encoding = "UTF-8")
View(test)
View(test)
test %>%
filter(municipio == "São Paulo")
test %>%
filter(municipio == "Sao Paulo")
test %>%
filter(cod_mun == 3550308)
test %>%
filter(cod_mun == 3509502)
test %>%
filter(cod_mun == 3304557)
